{"cells":[{"cell_type":"markdown","metadata":{"id":"fmms-YEH50sD"},"source":["# Imports"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":55793,"status":"ok","timestamp":1652723887638,"user":{"displayName":"Samuel Marks","userId":"03335611171483116507"},"user_tz":240},"id":"9e4PHSMY1AQF","outputId":"eafb9ebd-a328-48e7-9170-af6d688fcfd5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting einops\n","  Downloading einops-0.4.1-py3-none-any.whl (28 kB)\n","Installing collected packages: einops\n","Successfully installed einops-0.4.1\n","Mounted at /content/gdrive\n","/content/gdrive/MyDrive/mlab\n","Collecting transformers\n","  Downloading transformers-4.19.1-py3-none-any.whl (4.2 MB)\n","\u001b[K     |████████████████████████████████| 4.2 MB 4.4 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 36.0 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.6.0-py3-none-any.whl (84 kB)\n","\u001b[K     |████████████████████████████████| 84 kB 2.4 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 46.4 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.6.0 pyyaml-6.0 tokenizers-0.12.1 transformers-4.19.1\n","Collecting torchtyping\n","  Downloading torchtyping-0.1.4-py3-none-any.whl (17 kB)\n","Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from torchtyping) (1.11.0+cu113)\n","Collecting typeguard>=2.11.1\n","  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7.0->torchtyping) (4.2.0)\n","Installing collected packages: typeguard, torchtyping\n","  Attempting uninstall: typeguard\n","    Found existing installation: typeguard 2.7.1\n","    Uninstalling typeguard-2.7.1:\n","      Successfully uninstalled typeguard-2.7.1\n","Successfully installed torchtyping-0.1.4 typeguard-2.13.3\n"]}],"source":["# if running on Google colab\n","!pip install einops\n","import torch as t\n","from torch import einsum\n","from einops import rearrange, repeat, reduce\n","import math\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","%cd /content/gdrive/MyDrive/mlab/\n","\n","!pip install transformers\n","!pip install torchtyping\n","import days.w2d1.bert_tests as bert_tests\n","\n","# if running elsewhere, install dependencies (einops, transformers, torchyping), then:\n","\"\"\"\n","import torch as t\n","from torch import einsum\n","from einops import rearrange, repeat, reduce\n","import math\n","import bert_tests # this command might need to be fiddled with depending on where this file is stored\n","\"\"\""]},{"cell_type":"markdown","metadata":{"id":"7vYveFlf5-rx"},"source":["# Part 1: Attention"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1652723887644,"user":{"displayName":"Samuel Marks","userId":"03335611171483116507"},"user_tz":240},"id":"kaBgK5Gs6CtU","outputId":"1da7dbc4-bb10-4521-9137-8daa392c2b02"},"outputs":[{"name":"stdout","output_type":"stream","text":["attention pattern raw MATCH!!!!!!!!\n"," SHAPE (2, 12, 3, 3) MEAN: 0.006629 STD: 0.1046 VALS [0.04644 0.09279 -0.2193 0.05949 0.05956 0.1955 -0.09895 0.01574 -0.07148 -0.165...]\n"]}],"source":["# outputs pre-softmax attention scores \n","# as a Tensor of shape [batch_size, num_heads, seq_length (key), seq_length (query)]\n","def raw_attention_scores(token_activations, num_heads, project_query, project_key):\n","  queries = rearrange(project_query(token_activations), 'b sl (nh hs) -> b nh sl hs', nh=num_heads)\n","  keys    = rearrange(project_key(token_activations),   'b sl (nh hs) -> b nh sl hs', nh=num_heads)\n","  head_size = queries.size(-1)\n","  return einsum('bhqi,bhki->bhkq', queries, keys) / math.sqrt(head_size)\n","\n","bert_tests.test_attention_pattern_fn(raw_attention_scores)"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1652723887645,"user":{"displayName":"Samuel Marks","userId":"03335611171483116507"},"user_tz":240},"id":"l9hM91T2A7wl","outputId":"21654b26-fafa-4d8f-f5b3-133541a7bcc3"},"outputs":[{"name":"stdout","output_type":"stream","text":["attention MATCH!!!!!!!!\n"," SHAPE (2, 3, 768) MEAN: 0.001727 STD: 0.1128 VALS [0.08029 0.3392 0.0663 -0.1077 -0.009387 0.1234 0.1148 -0.2861 -0.07218 0.05894...]\n"]}],"source":["def bert_attention(token_activations, num_heads, attention_pattern, project_value, project_output):\n","  values = rearrange(project_value(token_activations), 'b sl (nh hs) -> b nh sl hs', nh=num_heads)\n","  attn_scores = attention_pattern.softmax(-2)\n","  attn = einsum('bhki,bhkq->bhqi', values, attn_scores)\n","  return project_output(rearrange(attn, 'b nh sl hs -> b sl (nh hs)'))\n","\n","bert_tests.test_attention_fn(bert_attention)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1392,"status":"ok","timestamp":1652723889020,"user":{"displayName":"Samuel Marks","userId":"03335611171483116507"},"user_tz":240},"id":"yuGlMQa7Fyni","outputId":"6dc6a578-9ab1-4426-e409-22deb8493240"},"outputs":[{"name":"stdout","output_type":"stream","text":["bert MATCH!!!!!!!!\n"," SHAPE (2, 3, 768) MEAN: -0.001554 STD: 0.1736 VALS [-0.08316 -0.09165 -0.03188 -0.03013 0.1001 0.09549 -0.1046 0.07742 0.0424 0.05553...]\n"]}],"source":["from torch import nn\n","\n","class MultiHeadedSelfAttention(nn.Module):\n","  def __init__(self, num_heads, hidden_size):\n","    super().__init__()\n","    self.head_size = 64\n","    self.num_heads = num_heads\n","    self.project_query = nn.Linear(hidden_size, num_heads * self.head_size)\n","    self.project_key   = nn.Linear(hidden_size, num_heads * self.head_size)\n","    self.project_value = nn.Linear(hidden_size, num_heads * self.head_size)\n","    self.project_output= nn.Linear(num_heads * self.head_size, hidden_size)\n","\n","  def forward(self, input):\n","    raw_scores = raw_attention_scores(input, self.num_heads, self.project_query, self.project_key)\n","    return bert_attention(input, self.num_heads, raw_scores, self.project_value, self.project_output)\n","\n","bert_tests.test_bert_attention(MultiHeadedSelfAttention)\n"]},{"cell_type":"markdown","metadata":{"id":"LKXICi-ZQRzA"},"source":["# Part 2: Transformer Encoder block"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":46,"status":"ok","timestamp":1652723889021,"user":{"displayName":"Samuel Marks","userId":"03335611171483116507"},"user_tz":240},"id":"cXQ5Xy_LQV2r","outputId":"a649788b-0c68-4379-af10-0b2847b7d0fa"},"outputs":[{"name":"stdout","output_type":"stream","text":["bert mlp MATCH!!!!!!!!\n"," SHAPE (2, 3, 768) MEAN: -0.0001934 STD: 0.1044 VALS [-0.1153 0.1189 -0.0813 0.1021 0.0296 0.06182 0.0341 0.1446 0.2622 -0.08507...]\n"]}],"source":["from torch.nn.functional import gelu\n","\n","def bert_mlp(token_activations, linear_1, linear_2):\n","  return linear_2(gelu(linear_1(token_activations)))\n","\n","bert_tests.test_bert_mlp(bert_mlp)"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":35,"status":"ok","timestamp":1652723889022,"user":{"displayName":"Samuel Marks","userId":"03335611171483116507"},"user_tz":240},"id":"X6TGbl3dQn5A"},"outputs":[],"source":["class BertMLP(nn.Module):\n","  def __init__(self, input_size, intermediate_size):\n","    super().__init__()\n","    self.linear_1 = nn.Linear(input_size, intermediate_size)\n","    self.linear_2 = nn.Linear(intermediate_size, input_size)\n","\n","  def forward(self, input):\n","    return bert_mlp(input, self.linear_1, self.linear_2)"]},{"cell_type":"code","execution_count":57,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1652727092143,"user":{"displayName":"Samuel Marks","userId":"03335611171483116507"},"user_tz":240},"id":"AwlSbIa3RyIS","outputId":"2cdc28c6-c9d7-4299-9595-1728efdae864"},"outputs":[{"name":"stdout","output_type":"stream","text":["layer norm MATCH!!!!!!!!\n"," SHAPE (20, 10) MEAN: -4.768e-09 STD: 1.003 VALS [1.126 0.6667 -0.174 1.782 -0.9279 -1.816 -0.578 0.5947 -0.2722 -0.4015...]\n"]}],"source":["class LayerNorm(nn.Module):\n","  def __init__(self, normalized_dim):\n","    super().__init__()\n","    self.weight = nn.Parameter(t.ones(normalized_dim))\n","    self.bias   = nn.Parameter(t.zeros(normalized_dim))\n","\n","  def forward(self, input):\n","    input = input - input.mean(-1, keepdim=True)\n","    input = input / (input.var(-1, keepdim=True, unbiased=False) + 1e-5).sqrt()\n","    return input * self.weight + self.bias\n","\n","bert_tests.test_layer_norm(LayerNorm)\n"]},{"cell_type":"code","execution_count":58,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":444,"status":"ok","timestamp":1652727096783,"user":{"displayName":"Samuel Marks","userId":"03335611171483116507"},"user_tz":240},"id":"WUrFqjjoViS9","outputId":"6a39bf83-9d1b-4dea-97f2-e4a7b56c52a7"},"outputs":[{"name":"stdout","output_type":"stream","text":["bert MATCH!!!!!!!!\n"," SHAPE (2, 3, 768) MEAN: 1.656e-09 STD: 1 VALS [0.007132 -0.04372 0.6502 -0.5972 -1.097 0.7267 0.1275 -0.6035 -0.2226 0.2145...]\n"]}],"source":["class BertBlock(nn.Module):\n","  def __init__(self, hidden_size, intermediate_size, num_heads, dropout):\n","    super().__init__()\n","    self.attention = MultiHeadedSelfAttention(num_heads, hidden_size)\n","    self.layer_norm1 = LayerNorm(hidden_size)\n","    self.mlp = BertMLP(hidden_size, intermediate_size)\n","    self.dropout = nn.Dropout(dropout)\n","    self.layer_norm2 = LayerNorm(hidden_size)\n","\n","  def forward(self, input):\n","    post_attn = self.layer_norm1(input + self.attention(input))\n","    return self.layer_norm2(post_attn + self.dropout(self.mlp(post_attn)))\n","\n","bert_tests.test_bert_block(BertBlock)\n"]},{"cell_type":"markdown","metadata":{"id":"bp0q8hccWsm2"},"source":["# Part 3: BERT Embedding"]},{"cell_type":"code","execution_count":59,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":719,"status":"ok","timestamp":1652727102145,"user":{"displayName":"Samuel Marks","userId":"03335611171483116507"},"user_tz":240},"id":"zSUoUPpgXoKh","outputId":"6d6c5137-8c3d-4639-e9d2-e46121132383"},"outputs":[{"name":"stdout","output_type":"stream","text":["embedding MATCH!!!!!!!!\n"," SHAPE (2, 3, 5) MEAN: -0.06748 STD: 1.062 VALS [1.176 -0.1914 0.8212 1.047 -0.481 0.7106 -1.304 -1.307 -0.438 -0.2764...]\n"]}],"source":["class Embedding(nn.Module):\n","  def __init__(self, vocab_size, embed_size):\n","    super().__init__()\n","    self.emb_matrix = nn.Parameter(t.randn(vocab_size, embed_size))\n","\n","  def forward(self, input):\n","    return self.emb_matrix[input]\n","\n","bert_tests.test_embedding(Embedding)"]},{"cell_type":"code","execution_count":60,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":566,"status":"ok","timestamp":1652727104654,"user":{"displayName":"Samuel Marks","userId":"03335611171483116507"},"user_tz":240},"id":"yN04M_ReXthR","outputId":"a137ade9-525d-488d-cebb-45be2a071605"},"outputs":[{"name":"stdout","output_type":"stream","text":["bert embedding MATCH!!!!!!!!\n"," SHAPE (2, 3, 768) MEAN: 8.278e-10 STD: 1 VALS [-1.319 -0.4378 -2.074 0.9679 0.9274 1.479 -0.501 -1.9 -0.212 0.7961...]\n"]}],"source":["def bert_embedding(\n","    input_ids,      # : [batch, seqlen]\n","    token_type_ids, # : [batch, seqlen]\n","    position_embedding,   # : Embedding\n","    token_embedding,      # : Embedding\n","    token_type_embedding, # : Embedding, \n","    layer_norm, # : LayerNorm, \n","    dropout     # : nn.Dropout\n","):\n","  seqlen = input_ids.size(1)\n","  positions = t.arange(0, seqlen, device=input_ids.device)\n","  emb = token_embedding(input_ids) + token_type_embedding(token_type_ids) + position_embedding(positions)\n","  return layer_norm(dropout(emb))\n","\n","bert_tests.test_bert_embedding_fn(bert_embedding)"]},{"cell_type":"code","execution_count":61,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":398,"status":"ok","timestamp":1652727105027,"user":{"displayName":"Samuel Marks","userId":"03335611171483116507"},"user_tz":240},"id":"etVgtmqlbge1","outputId":"c13fced0-0cce-47ad-b622-b0ce1db30209"},"outputs":[{"name":"stdout","output_type":"stream","text":["bert embedding MATCH!!!!!!!!\n"," SHAPE (2, 3, 768) MEAN: 1.242e-09 STD: 1 VALS [-0.009385 -0.4919 0.9852 -0.3535 -3.624 1.333 1.163 1.449 1.063 0.246...]\n"]}],"source":["class BertEmbedding(nn.Module):\n","  def __init__(self, vocab_size, hidden_size, max_position_embeddings, type_vocab_size, dropout):\n","    super().__init__()\n","    self.token_embedding      = Embedding(vocab_size, hidden_size)\n","    self.position_embedding   = Embedding(max_position_embeddings, hidden_size)\n","    self.token_type_embedding = Embedding(type_vocab_size, hidden_size)\n","    self.layer_norm = LayerNorm(hidden_size)\n","    self.dropout = nn.Dropout(dropout)\n","\n","  def forward(self, input_ids, token_type_ids):\n","    return bert_embedding(\n","        input_ids, \n","        token_type_ids,\n","        self.position_embedding,\n","        self.token_embedding,\n","        self.token_type_embedding,\n","        self.layer_norm,\n","        self.dropout)\n","    \n","bert_tests.test_bert_embedding(BertEmbedding)"]},{"cell_type":"markdown","metadata":{"id":"Ljbihka9dFvM"},"source":["# Part 4: Putting it all together"]},{"cell_type":"code","execution_count":62,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10850,"status":"ok","timestamp":1652727118978,"user":{"displayName":"Samuel Marks","userId":"03335611171483116507"},"user_tz":240},"id":"ydU1hBMKdDzM","outputId":"b4cdbe1b-83a7-41a1-88a6-3245a54aada8"},"outputs":[{"name":"stdout","output_type":"stream","text":["bert MATCH!!!!!!!!\n"," SHAPE (1, 4, 28996) MEAN: 0.003031 STD: 0.5765 VALS [-0.5742 -0.432 0.1186 -0.7165 -0.5261 0.4967 1.223 0.3165 -0.3247 -0.5716...]\n"]}],"source":["class Bert(nn.Module):\n","  def __init__(\n","      self, vocab_size, hidden_size, max_position_embeddings, type_vocab_size, \n","      dropout, intermediate_size, num_heads, num_layers: int\n","):\n","    super().__init__()\n","    self.embedding = BertEmbedding(\n","        vocab_size, hidden_size, max_position_embeddings, type_vocab_size, dropout)\n","    self.transformer = nn.Sequential(\n","        *[BertBlock(hidden_size, intermediate_size, num_heads, dropout) for _ in range(num_layers)])\n","    self.linear = nn.Linear(hidden_size, hidden_size)\n","    self.layer_norm = LayerNorm(hidden_size)\n","    self.unembed = nn.Linear(hidden_size, vocab_size)\n","\n","  def forward(self, input_ids):\n","    token_type_ids = t.zeros(*input_ids.shape, dtype=int, device=input_ids.device)\n","    return self.unembed(self.layer_norm(gelu(self.linear(self.transformer(self.embedding(input_ids, token_type_ids))))))\n","\n","bert_tests.test_bert(Bert)"]},{"cell_type":"markdown","metadata":{"id":"60VKM-17vdle"},"source":["# Step 5: Load pretrained weights"]},{"cell_type":"code","execution_count":63,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12610,"status":"ok","timestamp":1652727139868,"user":{"displayName":"Samuel Marks","userId":"03335611171483116507"},"user_tz":240},"id":"u8cjze_MhhKW","outputId":"eb837f14-a90b-4a99-a2a0-ae93ee9d384d"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["my_bert = Bert(\n","    vocab_size=28996, hidden_size=768, max_position_embeddings=512, \n","    type_vocab_size=2, dropout=0.1, intermediate_size=3072, \n","    num_heads=12, num_layers=12\n",")\n","pretrained_bert = bert_tests.get_pretrained_bert()"]},{"cell_type":"code","execution_count":64,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":513,"status":"ok","timestamp":1652727142191,"user":{"displayName":"Samuel Marks","userId":"03335611171483116507"},"user_tz":240},"id":"sonJ1N_dxn4J","outputId":"425724af-a57e-4b51-eed0-b9df5785a530"},"outputs":[{"name":"stdout","output_type":"stream","text":["classification_head.weight\n","classification_head.bias\n"]}],"source":["import re\n","def mapkey(k):\n","  k = k.replace('_embedding.weight', '_embedding.emb_matrix')\n","  k = k.replace('.pattern', '')\n","  k = k.replace('out', 'output')\n","  k = re.sub(r'(?<!(dual\\.|ding\\.))layer_norm', 'layer_norm1', k)\n","  k = re.sub(r'residual\\.mlp(?=[1-9])', 'mlp.linear_', k)\n","  k = re.sub(r'residual\\.layer_norm', 'layer_norm2', k)\n","  k = k.replace('lm_head.mlp', 'linear')\n","  k = k.replace('lm_head.layer_norm1', 'layer_norm')\n","  k = k.replace('lm_head.unembedding', 'unembed')\n","  k = re.sub(r'classification.*', '', k)\n","  return k\n","\n","for k in pretrained_bert.state_dict(): \n","  if mapkey(k) not in my_bert.state_dict(): print(k)\n","\n","# should only display the classification heads"]},{"cell_type":"code","execution_count":65,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":331,"status":"ok","timestamp":1652727145093,"user":{"displayName":"Samuel Marks","userId":"03335611171483116507"},"user_tz":240},"id":"YEh8QQqtDtUo","outputId":"f683bfcc-e008-42ac-d490-75a9a38d8c49"},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":65,"metadata":{},"output_type":"execute_result"}],"source":["load_dict = {}\n","for k,v in pretrained_bert.state_dict().items():\n","  load_dict[mapkey(k)] = v\n","load_dict.pop('') # get rid of the data for the classification heads\n","my_bert.load_state_dict(load_dict)"]},{"cell_type":"code","execution_count":66,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2819,"status":"ok","timestamp":1652727150629,"user":{"displayName":"Samuel Marks","userId":"03335611171483116507"},"user_tz":240},"id":"kA9GYBRjGDMe","outputId":"cb83b570-713f-485c-ac50-46c19357f840"},"outputs":[{"name":"stdout","output_type":"stream","text":["comparing Berts MATCH!!!!!!!!\n"," SHAPE (10, 20, 28996) MEAN: -2.732 STD: 2.413 VALS [-5.65 -6.041 -6.096 -6.062 -5.946 -5.777 -5.977 -6.015 -6.028 -5.935...]\n"]}],"source":["bert_tests.test_same_output(my_bert, pretrained_bert, tol=1e-4)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vKdI7IT6MVDl"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNLXsno0HR/Z1FyU51NHoDP","name":"w2d1.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.8.10"}},"nbformat":4,"nbformat_minor":0}
